{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a257f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeab1ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_py=pd.read_csv(\"../datasets/python-code.csv\")\n",
    "ds_path = Path(\"../datasets/ds-code.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06eae259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_py.head()\n",
    "df_py.isna().sum()\n",
    "df_py.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b87c81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total records:  17311\n",
      "{'code_len': 745,\n",
      " 'dataset': 'code-instructions-122k-alpaca-style',\n",
      " 'has_comp': False,\n",
      " 'has_ml': True,\n",
      " 'has_nn': True,\n",
      " 'has_plt': False,\n",
      " 'has_wrang': False,\n",
      " 'input': '',\n",
      " 'instruction': 'Design a neural network model to classify emails into spam '\n",
      "                'and non-spam.',\n",
      " 'instruction_len': 72,\n",
      " 'lang': 'python',\n",
      " 'mean_ln_len': 30.0833333333,\n",
      " 'nl_ratio': 0.1651006711,\n",
      " 'output': 'import tensorflow as tf\\n'\n",
      "           'from tensorflow.keras.layers import Dense, Input\\n'\n",
      "           '\\n'\n",
      "           '# Preparing data\\n'\n",
      "           'X_train, y_train, X_test, y_test = get_data() # Returns training '\n",
      "           'and testing datasets\\n'\n",
      "           '\\n'\n",
      "           '# Building model\\n'\n",
      "           'inputs = Input(shape=(X_train.shape[1], ))\\n'\n",
      "           \"x = Dense(64, activation='relu')(inputs)\\n\"\n",
      "           \"x = Dense(32, activation='relu')(x)\\n\"\n",
      "           \"predictions = Dense(1, activation='sigmoid')(x)\\n\"\n",
      "           '\\n'\n",
      "           '# Compiling model\\n'\n",
      "           'model = tf.keras.Model(inputs=inputs, outputs=predictions)\\n'\n",
      "           \"model.compile(optimizer='adam',\\n\"\n",
      "           \"              loss='binary_crossentropy',\\n\"\n",
      "           \"              metrics=['accuracy'])\\n\"\n",
      "           '\\n'\n",
      "           '# Training the model\\n'\n",
      "           'model.fit(X_train, y_train, epochs=30, batch_size=32)\\n'\n",
      "           '\\n'\n",
      "           '# Evaluating the model\\n'\n",
      "           'scores = model.evaluate(X_test, y_test, verbose=0)\\n'\n",
      "           'print(\"Accuracy: %.2f%%\" % (scores[1]*100))',\n",
      " 'text': 'Below is an instruction that describes a task. Write a response that '\n",
      "         'appropriately completes the request. ### Instruction: Design a '\n",
      "         'neural network model to classify emails into spam and non-spam. ### '\n",
      "         'Input: No input ### Output: import tensorflow as tf\\n'\n",
      "         'from tensorflow.keras.layers import Dense, Input\\n'\n",
      "         '\\n'\n",
      "         '# Preparing data\\n'\n",
      "         'X_train, y_train, X_test, y_test = get_data() # Returns training and '\n",
      "         'testing datasets\\n'\n",
      "         '\\n'\n",
      "         '# Building model\\n'\n",
      "         'inputs = Input(shape=(X_train.shape[1], ))\\n'\n",
      "         \"x = Dense(64, activation='relu')(inputs)\\n\"\n",
      "         \"x = Dense(32, activation='relu')(x)\\n\"\n",
      "         \"predictions = Dense(1, activation='sigmoid')(x)\\n\"\n",
      "         '\\n'\n",
      "         '# Compiling model\\n'\n",
      "         'model = tf.keras.Model(inputs=inputs, outputs=predictions)\\n'\n",
      "         \"model.compile(optimizer='adam',\\n\"\n",
      "         \"              loss='binary_crossentropy',\\n\"\n",
      "         \"              metrics=['accuracy'])\\n\"\n",
      "         '\\n'\n",
      "         '# Training the model\\n'\n",
      "         'model.fit(X_train, y_train, epochs=30, batch_size=32)\\n'\n",
      "         '\\n'\n",
      "         '# Evaluating the model\\n'\n",
      "         'scores = model.evaluate(X_test, y_test, verbose=0)\\n'\n",
      "         'print(\"Accuracy: %.2f%%\" % (scores[1]*100))',\n",
      " 'topics': 'nn,ml'}\n"
     ]
    }
   ],
   "source": [
    "with ds_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    ds_data=[json.loads(line) for line in f]\n",
    "\n",
    "print(\"total records: \", len(ds_data))\n",
    "pprint(ds_data[0], depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79abaf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_py[\"Input\"]=df_py[\"Input\"].fillna(\"\")\n",
    "df_py=df_py.rename(columns={\n",
    "    \"Input\": \"input\",\n",
    "    \"Output\": \"output\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b16f03ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_data=[]\n",
    "for _, row in df_py.iterrows():\n",
    "    entry={\n",
    "        \"prompt\": f\"### Instruction:\\n{row['Instruction']}\\n\\n### Input:\\n{row['input']}\\n\\n### Response:\\n\",\n",
    "        \"response\": row['output']\n",
    "    }\n",
    "    python_data.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffaa4804",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"../processed-data\").mkdir(exist_ok=True)\n",
    "with open(\"../processed-data/python_instruct.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in python_data:\n",
    "        f.write(json.dumps(item, ensure_ascii=False)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89a570ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return (\n",
    "        text.replace(\"\\u2028\", \" \").replace(\"\\u2029\", \" \").replace(\"\\r\", \"\").strip()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac5adcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_data=[]\n",
    "with open(\"../datasets/ds-code.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        ds_data.append(data)\n",
    "\n",
    "ds_clean=[]\n",
    "for item in ds_data:\n",
    "    instruction=clean_text(item.get(\"instruction\", \"\").strip())\n",
    "    input_=clean_text(item.get(\"input\", \"\").strip())\n",
    "    output=clean_text(item.get(\"output\", \"\").strip())\n",
    "\n",
    "    formatted={\n",
    "        \"prompt\": f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_}\\n\\n### Response:\\n\",\n",
    "        \"response\": output\n",
    "    }\n",
    "    ds_clean.append(formatted)\n",
    "\n",
    "with open(\"../processed-data/ds_coder_instruct.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in ds_clean:\n",
    "        f.write(json.dumps(item, ensure_ascii=False)+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
